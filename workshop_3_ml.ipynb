{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workshop-3-ml.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNppIr+NYRTMVDT4Rm9grwQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkrobinette/workshops/blob/main/workshop_3_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH98HGO9X3Ot"
      },
      "source": [
        "# Workshop 3: Machine Learning\n",
        "**Acknowlegements:** Resources modified from [scikit learn tutorial](https://scikit-learn.org/stable/tutorial/basic/tutorial.html#machine-learning-the-problem-setting)\n",
        "\n",
        "- Directions: Follow along in order with the following code blocks. To run a code block, do one of the following:\n",
        "1.   Hover over the block and click the black circle\n",
        "2.   Press shift -> enter\n",
        "\n",
        "If more information is needed on Python, check out the following sites:\n",
        "\n",
        "*   [Python Installation](https://docs.anaconda.com/anaconda/install/) using Anaconda\n",
        "*   More information about [Python](https://www.python.org/)\n",
        "*   A [great resource](https://swcarpentry.github.io/python-novice-inflammation/setup.html) for learning Python basics, includes tutorials and setup\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJrWViNybGce"
      },
      "source": [
        "\n",
        "## Loading Example Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKKR5P_vTEcm"
      },
      "source": [
        "# Import necessary libraries for downloading datasets\n",
        "from sklearn import datasets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZqVatVKbRB8"
      },
      "source": [
        "\n",
        "`scikit-learn` comes with a few standard datasets, for instance the iris and digits datasets for classification and the diabetes dataset for regression.\n",
        "\n",
        "The iris dataset:\n",
        "\n",
        "* Consists of 3 different types of irises' (Setosa, Versicolour, and Virginica) petal and sepal length \n",
        "*  Rows are the respective samples\n",
        "*  Columns are Sepal Length, Sepal Width, Petal Length and Petal Width\n",
        "\n",
        "The digits dataset:\n",
        "- Consists of 1797 8x8 images\n",
        "- Each image is of a hand-written digit\n",
        "- 8x8 image is often represented by vector of length 64\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5Zp4jC0TjIn"
      },
      "source": [
        "# loading the iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# loading the digits dataset\n",
        "digits = datasets.load_digits()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcHNV-8KfCCN"
      },
      "source": [
        "### Exercise 1:\n",
        "---\n",
        "> Using the above notation, load the `wine` dataset into a variable named `wine`. You can check your implementation in the `Answers` section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6N6t22TTnTk"
      },
      "source": [
        "# load the wine dataset\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT40BumRgG0c"
      },
      "source": [
        "## Exploring Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TCPfXH3frLP"
      },
      "source": [
        "A dataset is a dictionary-like object that holds all the data and some metadata about the data. This data is stored in the .data member, which is a n_samples, n_features array. In the case of supervised problem, one or more response variables are stored in the .target member. \n",
        "- the rows are each of the samples\n",
        "- the columns are each of the features\n",
        "\n",
        "\n",
        "> | Dataset Functions| Info                                           |\n",
        "|--------------------|------------------------------------------------|\n",
        "| .data              | The samples and features for each sample       |\n",
        "| .feature_names     | Access the names of the features of the dataset|\n",
        "| .target            | Access the actual labels for each sample       |\n",
        "| .target_names      | Access the label type for each of the targets  |\n",
        "| .data.shape        | The shape of the data vector                   |\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNHbhpq_eYrh"
      },
      "source": [
        "# the iris data\n",
        "print(iris.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyR8tPjEiF89",
        "outputId": "b0093b48-abb4-4819-bf7c-44c45d39b4cb"
      },
      "source": [
        "# the feature names\n",
        "print(iris.feature_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anh2YmQmhXu1"
      },
      "source": [
        "The targets are the actual labels of each of the samples. Each numerical label corresponds to flower type (Setosa, Versicolour, Virginica)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Ww952vhdCW"
      },
      "source": [
        "# print targets\n",
        "print(iris.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxrlxzEaiTaY",
        "outputId": "c73f15eb-5fcf-4cc6-c789-d9e12f03091a"
      },
      "source": [
        "# print target labels and names from iris dataset\n",
        "print(\"Target labels and names:\")\n",
        "for item in range(len(iris.target_names)):\n",
        "  print( \"%s = %s\" %(item, iris.target_names[item]))\n",
        "  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target labels and names:\n",
            "0 = setosa\n",
            "1 = versicolor\n",
            "2 = virginica\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpHFdOg-hwdC"
      },
      "source": [
        "### Exercise 2:\n",
        "---\n",
        "\n",
        "> 1. Print the data of the digits dataset\n",
        "2. Print the shape of data in the digits dataset\n",
        "3. Print only the first sample of the digits dataset\n",
        "4. Print the targets of the digits dataset\n",
        "5. Print the target names of the digits dataset\n",
        "\n",
        "Check your implementation in the `Answers` section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VPh1cdsTqAz"
      },
      "source": [
        "# print the digits data\n",
        "\n",
        "# print the shape of data in the dataset\n",
        "\n",
        "#print only the first sample of the digits dataset\n",
        "\n",
        "#print the targets\n",
        "\n",
        "# print the feature names\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ_wp9Vnm8e9"
      },
      "source": [
        "## Splitting the Data\n",
        "\n",
        "To be able to evaluate your model, you need to split your data into a training and testing set. Some people will also include a validation set. The training set is used to fit a model using and the testing set is used to evaluate that model. A common split is 80% training and 20% testing.\n",
        "\n",
        "The scikit-learn library gives us an easy way to split datasets with `train_test_split()`. This function needs 3 parameters: features, target, and test_set size. Additionally, you can use random_state to select records randomly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpB-wriLn7f3"
      },
      "source": [
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2,random_state= 4)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBFcBz81oMxl"
      },
      "source": [
        "This notation can be a little confusing at first. Below are what each of these new datasets are used for.\n",
        "\n",
        "> X_train: the features of the training set.\n",
        "\n",
        "> y_train: the actual labels of the data in X_train\n",
        "\n",
        "> X_test: the features of the testing set\n",
        "\n",
        "> y_test: the actual labels of the data in X_test\n",
        "\n",
        "It helps to remember that we will use fit(X, y), which finds a function that maps inputs (X) to output labels (y).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40yDEO3zqIcT"
      },
      "source": [
        "### Exercise 3:\n",
        "---\n",
        "> 1. print the shape of each of the new datasets\n",
        "2. Change the test_size and repeat\n",
        "3. Change the random_state number and repeat\n",
        "\n",
        "Check you answers in `Answers` section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVrXvB3coif9"
      },
      "source": [
        "# print the shape of the training and testing data\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr48E8Vij0I1"
      },
      "source": [
        "## Learning and Predicting\n",
        "\n",
        "In the case of the digits dataset, the task is to predict, given an image, which digit it represents. We are given samples of each of the 10 possible classes (the digits zero through nine) on which we fit an estimator to be able to predict the classes to which unseen samples belong.\n",
        "\n",
        "In scikit-learn, an estimator for classification is a Python object that implements the methods fit(X, y) and predict(T). *Fit is creating a function that maps inputs (X) to labels (y). Predict then takes this function and returns a predicted label for a given sample T.*\n",
        "\n",
        "An example of an estimator is the class sklearn.svm.SVC, which implements support vector classification. The estimator’s constructor takes as arguments the model’s parameters.\n",
        "\n",
        "For now, we will consider the estimator as a black box:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcTJWTH1UCvK"
      },
      "source": [
        "# import the support vector machine library (svm) from sklearn\n",
        "from sklearn import svm\n",
        "\n",
        "# clf = classifier\n",
        "clf = svm.SVC(kernel = 'linear')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zo73RT6rWbj"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiZECSMPUJxU",
        "outputId": "fde99082-df2d-4875-d340-fcdd98122fdc"
      },
      "source": [
        "# fit a function that maps inputs to outputs\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAGULSfdrhDe"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3_kHmWjUPou"
      },
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# now compare predictions to actual labels. \n",
        "# This will be True if the predicted value is equal to the actual value.\n",
        "# Else it will be False.\n",
        "results = [y_pred == y_test]\n",
        "\n",
        "# print the results\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ7QA73NsXLw"
      },
      "source": [
        "## Evaluate Model\n",
        "Scikit-learn also has some pretty handy built-in functions for evaluating models.\n",
        "\n",
        "> `metrics.accuracy_score(y_test, y_pred)` : returns the percentage of correct predictions compared to actual labels\n",
        "\n",
        "> `metrics.precision_score(y_test, y_pred)` : What proportion of positive identifications was actually correct?\n",
        "\n",
        "> `metrics.recall_score(y_test, y_pred)` : What proportion of actual positives was identified correctly?\n",
        "\n",
        "> `metrics.confusion_matrix(y_test, y_pred)` : Each Column is the predicted label (0-9), each row is the actual label (0-9). This allows us to easily evaluate where our model is commonly making mistakes.\n",
        "\n",
        "> `metrics.plot_confusion_matrix(y_test, y_pred)` : fancier version of above\n",
        "\n",
        "> ` metrics.classification_report(y_test, y_pred, digits=10)`: Pretty much every metric combined.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3IotxbltTIh"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# print accuracy\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# fancier confusion matrix\n",
        "disp = metrics.plot_confusion_matrix(clf, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "\n",
        "# Print the precision and recall, among other metrics\n",
        "print(metrics.classification_report(y_test, y_pred, digits=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee0ZwMAZV4-e"
      },
      "source": [
        "### Exercise 4: \n",
        "---\n",
        "The above model uses the 'linear' kernal to train but this parameter can also be:\n",
        "- polynomial : `'poly'`\n",
        "- sigmoid : `'sigmoid'`\n",
        "- radial basis function : `'rbf'`\n",
        "\n",
        "> 1. Change the kernel parameter to each of these values and see how your accuracy and confusion matrix changes.\n",
        "\n",
        "The degree of the polynomial function can also be set.\n",
        "> 2. Explore and evaluate different polynomial functions with varying degrees. How do these affect the model? e.g. `(clf = svm.SVC(kernel = 'poly', degree = 2)`\n",
        "\n",
        "A common problem in training is overfitting. This is when the function that maps inputs to outputs overfits to the training data. When new predictions are made using the trained model, they do not perform well because they follow too closely to the training scenarios. \n",
        "> 3. For more information and examples on overfitting and underfitting, check out this [website](https://keeeto.github.io/blog/bias_variance/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58EkPOscTOc8"
      },
      "source": [
        "### Exercise 5:\n",
        "---\n",
        "> 1. load the `*breast_cancer*` dataset into a variable named cancer\n",
        "> 2. Explore the datasets features and target names\n",
        "> 2. Split the data into 70% training and 30% testing\n",
        "> 3. make an instance of the svm.SVC classifier that uses the polynomial kernel with degree 2.\n",
        "> 4. Train the model\n",
        "> 5. Make predictions on the test set\n",
        "> 5. Evaluate the model's accuracy, and confusion matrix\n",
        "> 8. In this example, consider the following:\n",
        "  - false positives : something is predicted as benign that is actually malignant\n",
        "  - false negatives : something that is predicted as malignant but is actually benign\n",
        "  - Which would you rather avoid in this particular example? It is important to note that you can train a model with these types of situations in mind.\n",
        "\n",
        "\n",
        "Check answers in the `Answers` section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS28EtZGmxH2"
      },
      "source": [
        "# Load the cancer dataset\n",
        "\n",
        "\n",
        "# explore the data\n",
        "\n",
        "\n",
        "# split the data into training and testing\n",
        "\n",
        "\n",
        "# initialize classifier with polynomial kernel of degree 2\n",
        "\n",
        "\n",
        "# train the model\n",
        "\n",
        "\n",
        "# predictions\n",
        "\n",
        "\n",
        "# evaluate the model\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0L6k4LBbpUf"
      },
      "source": [
        "---\n",
        "# Answers\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO2fN-mjb1Xx"
      },
      "source": [
        "## Exercise 1:\n",
        "> Using the above notation, load the `wine` dataset into a variable named `wine`. You can check your implementation in the `Answers` section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_c29nEpcQ0y"
      },
      "source": [
        "# load the wine dataset\n",
        "wine = datasets.load_wine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_Udamjnb5Mu"
      },
      "source": [
        "## Exercise 2:\n",
        "> 1. Print the data of the digits dataset\n",
        "2. Print the shape of data in the digits dataset\n",
        "3. Print only the first sample of the digits dataset\n",
        "4. Print the targets of the digits dataset\n",
        "5. Print the target names of the digits dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db0Niuuacd20"
      },
      "source": [
        "# print the digits data\n",
        "print(digits.data)\n",
        "# print the shape of data in the dataset\n",
        "print(digits.data.shape)\n",
        "#print only the first sample of the digits dataset\n",
        "print(digits.data[0])\n",
        "#print the targets\n",
        "print(digits.target)\n",
        "# print the feature names\n",
        "print(digits.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrt3kMs4b8Eb"
      },
      "source": [
        "## Exercise 3: \n",
        "> 1. print the shape of each of the new datasets\n",
        "2. Change the test_size and repeat\n",
        "3. Change the random_state number and repeat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpEqByEAcoCQ"
      },
      "source": [
        "# print the shape of the training data\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq1OF40yb94N"
      },
      "source": [
        "## Exercise 4: \n",
        "The above model uses the 'linear' kernal to train but this parameter can also be:\n",
        "- polynomial : `'poly'`\n",
        "- sigmoid : `'sigmoid'`\n",
        "- radial basis function : `'rbf'`\n",
        "\n",
        "> 1. Change the kernel parameter to each of these values and see how your accuracy and confusion matrix changes.\n",
        "\n",
        "The degree of the polynomial function can also be set.\n",
        "> 2. Explore and evaluate different polynomial functions with varying degrees. How do these affect the model? e.g. `(clf = svm.SVC(kernel = 'poly', degree = 2)`\n",
        "\n",
        "A common problem in training is overfitting. This is when the function that maps inputs to outputs overfits to the training data. When new predictions are made using the trained model, they do not perform well because they follow too closely to the training scenarios. \n",
        "> 3. For more information and examples on overfitting and underfitting, check out this [website](https://keeeto.github.io/blog/bias_variance/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jomo_n5pcxY8"
      },
      "source": [
        "# examples\n",
        "clf = svm.SVC(kernel='poly')\n",
        "clf = svm.SVC(kernel='sigmoid')\n",
        "clf = svm.SVC(kernel = 'rbf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByXsQ--2b_YJ"
      },
      "source": [
        "## Exercise 5: \n",
        "> 1. load the `*breast_cancer*` dataset into a variable named cancer\n",
        "> 2. Explore the datasets features and target names\n",
        "> 2. Split the data into 70% training and 30% testing\n",
        "> 3. make an instance of the svm.SVC classifier that uses the polynomial kernel with degree 2.\n",
        "> 4. Train the model\n",
        "> 5. Make predictions on the test set\n",
        "> 5. Evaluate the model's accuracy, and confusion matrix\n",
        "> 8. In this example, consider the following:\n",
        "  - false positives : something is predicted as benign that is actually malignant\n",
        "  - false negatives : something that is predicted as malignant but is actually benign\n",
        "  - Which would you rather avoid in this particular example? It is important to note that you can train a model with these types of situations in mind."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkWPkl_LdCvA"
      },
      "source": [
        "# Load the cancer dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "\n",
        "# explore the data\n",
        "print(cancer.feature_names)\n",
        "print(cancer.target_names)\n",
        "print(cancer.data.shape)\n",
        "print(cancer.data)\n",
        "\n",
        "# split the data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size = 0.3, random_state = 10)\n",
        "\n",
        "# initialize classifier with polynomial kernel of degree 2\n",
        "clf = svm.SVC(kernel = 'poly', degree=2)\n",
        "\n",
        "# train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# evaluate the model\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_pred, y_test))\n",
        "disp = metrics.plot_confusion_matrix(clf, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred, digits=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWKY2WwrdHG_"
      },
      "source": [
        "8. In this instance, we would want to avoid false positives. It would be much worse to miss something cancerous than to misslabel something as cancerous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09J-nKscdUhG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}